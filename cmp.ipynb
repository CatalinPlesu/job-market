{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ac59d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# ============================================\n",
    "# SCAN CMP FOLDER\n",
    "# ============================================\n",
    "CMP_DIR = Path(\"cmp\")\n",
    "\n",
    "if not CMP_DIR.exists():\n",
    "    print(\"‚ùå /cmp folder not found!\")\n",
    "    exit()\n",
    "\n",
    "results = []\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"Scanning /cmp folder for results...\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for model_dir in CMP_DIR.iterdir():\n",
    "    if not model_dir.is_dir():\n",
    "        continue\n",
    "    \n",
    "    model_name = model_dir.name\n",
    "    result = {\n",
    "        \"model\": model_name,\n",
    "        \"time\": None,\n",
    "        \"status\": None,\n",
    "        \"response_type\": None\n",
    "    }\n",
    "    \n",
    "    # Read time\n",
    "    time_file = model_dir / \"time.txt\"\n",
    "    if time_file.exists():\n",
    "        with open(time_file, \"r\", encoding=\"utf-8\") as f:\n",
    "            lines = f.readlines()\n",
    "            for line in lines:\n",
    "                if \"Execution Time:\" in line:\n",
    "                    try:\n",
    "                        result[\"time\"] = float(line.split(\":\")[1].strip().split()[0])\n",
    "                    except:\n",
    "                        pass\n",
    "                if \"Response Status:\" in line:\n",
    "                    try:\n",
    "                        result[\"status\"] = int(line.split(\":\")[1].strip())\n",
    "                    except:\n",
    "                        pass\n",
    "    \n",
    "    # Check response type\n",
    "    if (model_dir / \"response.json\").exists():\n",
    "        result[\"response_type\"] = \"json\"\n",
    "    elif (model_dir / \"response.txt\").exists():\n",
    "        result[\"response_type\"] = \"txt\"\n",
    "    elif (model_dir / \"error.txt\").exists():\n",
    "        result[\"response_type\"] = \"error\"\n",
    "    else:\n",
    "        result[\"response_type\"] = \"unknown\"\n",
    "    \n",
    "    results.append(result)\n",
    "    print(f\"‚úì {model_name}: {result['time']}s, {result['response_type']}\")\n",
    "\n",
    "print(f\"\\nüìä Found {len(results)} model results\")\n",
    "\n",
    "# ============================================\n",
    "# PREPARE DATA FOR PLOTTING\n",
    "# ============================================\n",
    "models = [r[\"model\"] for r in results]\n",
    "times = [r[\"time\"] if r[\"time\"] is not None else 0 for r in results]\n",
    "response_types = [r[\"response_type\"] for r in results]\n",
    "\n",
    "# Create color mapping for response types\n",
    "color_map = {\n",
    "    \"json\": \"green\",\n",
    "    \"txt\": \"orange\", \n",
    "    \"error\": \"red\",\n",
    "    \"unknown\": \"gray\"\n",
    "}\n",
    "colors = [color_map.get(rt, \"gray\") for rt in response_types]\n",
    "\n",
    "# ============================================\n",
    "# PLOT 1: EXECUTION TIME BAR CHART\n",
    "# ============================================\n",
    "fig1, ax1 = plt.subplots(figsize=(14, max(6, len(models) * 0.5)))\n",
    "\n",
    "# Sort by time for better visualization\n",
    "sorted_indices = np.argsort(times)\n",
    "sorted_models = [models[i] for i in sorted_indices]\n",
    "sorted_times = [times[i] for i in sorted_indices]\n",
    "sorted_colors = [colors[i] for i in sorted_indices]\n",
    "\n",
    "bars = ax1.barh(sorted_models, sorted_times, color=sorted_colors, alpha=0.7, edgecolor='black', linewidth=0.5)\n",
    "ax1.set_xlabel(\"Execution Time (seconds)\", fontsize=13, fontweight='bold')\n",
    "ax1.set_ylabel(\"Model\", fontsize=13, fontweight='bold')\n",
    "ax1.set_title(\"LLM Model Execution Time Comparison\", fontsize=16, fontweight=\"bold\", pad=20)\n",
    "ax1.grid(axis='x', alpha=0.3, linestyle='--')\n",
    "\n",
    "# Add value labels on bars\n",
    "for i, (bar, time) in enumerate(zip(bars, sorted_times)):\n",
    "    if time > 0:\n",
    "        ax1.text(time + max(sorted_times) * 0.02, i, f\"{time:.2f}s\", \n",
    "                va='center', fontsize=10, fontweight='bold')\n",
    "\n",
    "# Add legend for colors\n",
    "from matplotlib.patches import Patch\n",
    "legend_elements = [\n",
    "    Patch(facecolor=color_map['json'], label='Valid JSON', alpha=0.7),\n",
    "    Patch(facecolor=color_map['txt'], label='Invalid JSON (Text)', alpha=0.7),\n",
    "    Patch(facecolor=color_map['error'], label='Error', alpha=0.7),\n",
    "    Patch(facecolor=color_map['unknown'], label='Unknown', alpha=0.7)\n",
    "]\n",
    "ax1.legend(handles=legend_elements, loc='lower right', fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(CMP_DIR / \"execution_time_comparison.png\", dpi=300, bbox_inches='tight')\n",
    "print(f\"\\nüìà Execution time plot saved to: {(CMP_DIR / 'execution_time_comparison.png').absolute()}\")\n",
    "plt.show()\n",
    "\n",
    "# ============================================\n",
    "# PLOT 2: RESPONSE TYPE DISTRIBUTION\n",
    "# ============================================\n",
    "response_type_counts = {\n",
    "    \"json\": response_types.count(\"json\"),\n",
    "    \"txt\": response_types.count(\"txt\"),\n",
    "    \"error\": response_types.count(\"error\"),\n",
    "    \"unknown\": response_types.count(\"unknown\")\n",
    "}\n",
    "\n",
    "# Filter out zero counts\n",
    "response_type_counts = {k: v for k, v in response_type_counts.items() if v > 0}\n",
    "\n",
    "fig2, ax2 = plt.subplots(figsize=(10, 8))\n",
    "\n",
    "wedges, texts, autotexts = ax2.pie(\n",
    "    response_type_counts.values(),\n",
    "    labels=[k.upper() for k in response_type_counts.keys()],\n",
    "    colors=[color_map[k] for k in response_type_counts.keys()],\n",
    "    autopct='%1.1f%%',\n",
    "    startangle=90,\n",
    "    textprops={'fontsize': 12, 'fontweight': 'bold'},\n",
    "    explode=[0.05] * len(response_type_counts)  # Slightly separate slices\n",
    ")\n",
    "\n",
    "ax2.set_title(\"Response Type Distribution\", fontsize=16, fontweight=\"bold\", pad=20)\n",
    "\n",
    "# Make percentage text bold and white\n",
    "for autotext in autotexts:\n",
    "    autotext.set_color('white')\n",
    "    autotext.set_fontweight('bold')\n",
    "    autotext.set_fontsize(14)\n",
    "\n",
    "# Make label text bold\n",
    "for text in texts:\n",
    "    text.set_fontweight('bold')\n",
    "    text.set_fontsize(12)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(CMP_DIR / \"response_type_distribution.png\", dpi=300, bbox_inches='tight')\n",
    "print(f\"üìà Response type plot saved to: {(CMP_DIR / 'response_type_distribution.png').absolute()}\")\n",
    "plt.show()\n",
    "\n",
    "# ============================================\n",
    "# PRINT SUMMARY STATISTICS\n",
    "# ============================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SUMMARY STATISTICS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "valid_times = [t for t in times if t > 0]\n",
    "if valid_times:\n",
    "    print(f\"\\n‚è±Ô∏è  Execution Time:\")\n",
    "    print(f\"   Fastest: {min(valid_times):.2f}s ({models[times.index(min(valid_times))]})\")\n",
    "    print(f\"   Slowest: {max(valid_times):.2f}s ({models[times.index(max(valid_times))]})\")\n",
    "    print(f\"   Average: {np.mean(valid_times):.2f}s\")\n",
    "    print(f\"   Median: {np.median(valid_times):.2f}s\")\n",
    "\n",
    "print(f\"\\n‚úÖ Response Types:\")\n",
    "for rtype, count in response_type_counts.items():\n",
    "    print(f\"   {rtype.upper()}: {count} ({count/len(results)*100:.1f}%)\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"DETAILED RESULTS\")\n",
    "print(\"=\"*80)\n",
    "for result in results:\n",
    "    status_icon = \"‚úÖ\" if result[\"response_type\"] == \"json\" else (\"‚ö†Ô∏è\" if result[\"response_type\"] == \"txt\" else \"‚ùå\")\n",
    "    time_str = f\"{result['time']:.2f}s\" if result['time'] else \"N/A\"\n",
    "    print(f\"{status_icon} {result['model']}\")\n",
    "    print(f\"   Time: {time_str} | Type: {result['response_type']} | Status: {result['status']}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74b322be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# ============================================\n",
    "# SCAN CMP FOLDER\n",
    "# ============================================\n",
    "CMP_DIR = Path(\"cmp\")\n",
    "\n",
    "if not CMP_DIR.exists():\n",
    "    print(\"‚ùå /cmp folder not found!\")\n",
    "    exit()\n",
    "\n",
    "results = []\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"Scanning /cmp folder for results...\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for model_dir in CMP_DIR.iterdir():\n",
    "    if not model_dir.is_dir():\n",
    "        continue\n",
    "    \n",
    "    model_name = model_dir.name\n",
    "    result = {\n",
    "        \"model\": model_name,\n",
    "        \"time\": None,\n",
    "        \"status\": None,\n",
    "        \"response_type\": None\n",
    "    }\n",
    "    \n",
    "    # Read time\n",
    "    time_file = model_dir / \"time.txt\"\n",
    "    if time_file.exists():\n",
    "        with open(time_file, \"r\", encoding=\"utf-8\") as f:\n",
    "            lines = f.readlines()\n",
    "            for line in lines:\n",
    "                if \"Execution Time:\" in line:\n",
    "                    try:\n",
    "                        result[\"time\"] = float(line.split(\":\")[1].strip().split()[0])\n",
    "                    except:\n",
    "                        pass\n",
    "                if \"Response Status:\" in line:\n",
    "                    try:\n",
    "                        result[\"status\"] = int(line.split(\":\")[1].strip())\n",
    "                    except:\n",
    "                        pass\n",
    "    \n",
    "    # Check response type\n",
    "    if (model_dir / \"response.json\").exists():\n",
    "        result[\"response_type\"] = \"json\"\n",
    "    elif (model_dir / \"response.txt\").exists():\n",
    "        result[\"response_type\"] = \"txt\"\n",
    "    elif (model_dir / \"error.txt\").exists():\n",
    "        result[\"response_type\"] = \"error\"\n",
    "    else:\n",
    "        result[\"response_type\"] = \"unknown\"\n",
    "    \n",
    "    results.append(result)\n",
    "    print(f\"‚úì {model_name}: {result['time']}s, {result['response_type']}\")\n",
    "\n",
    "print(f\"\\nüìä Found {len(results)} model results\")\n",
    "\n",
    "# ============================================\n",
    "# PREPARE DATA FOR PLOTTING\n",
    "# ============================================\n",
    "models = [r[\"model\"] for r in results]\n",
    "times = [r[\"time\"] if r[\"time\"] is not None else 0 for r in results]\n",
    "response_types = [r[\"response_type\"] for r in results]\n",
    "\n",
    "# Create color mapping for response types\n",
    "color_map = {\n",
    "    \"json\": \"green\",\n",
    "    \"txt\": \"orange\", \n",
    "    \"error\": \"red\",\n",
    "    \"unknown\": \"gray\"\n",
    "}\n",
    "colors = [color_map.get(rt, \"gray\") for rt in response_types]\n",
    "\n",
    "# ============================================\n",
    "# PLOT 1: EXECUTION TIME BAR CHART\n",
    "# ============================================\n",
    "fig1, ax1 = plt.subplots(figsize=(14, max(6, len(models) * 0.5)))\n",
    "\n",
    "# Sort by time for better visualization\n",
    "sorted_indices = np.argsort(times)\n",
    "sorted_models = [models[i] for i in sorted_indices]\n",
    "sorted_times = [times[i] for i in sorted_indices]\n",
    "sorted_colors = [colors[i] for i in sorted_indices]\n",
    "\n",
    "bars = ax1.barh(sorted_models, sorted_times, color=sorted_colors, alpha=0.7, edgecolor='black', linewidth=0.5)\n",
    "ax1.set_xlabel(\"Execution Time (seconds)\", fontsize=13, fontweight='bold')\n",
    "ax1.set_ylabel(\"Model\", fontsize=13, fontweight='bold')\n",
    "ax1.set_title(\"LLM Model Execution Time Comparison\", fontsize=16, fontweight=\"bold\", pad=20)\n",
    "ax1.grid(axis='x', alpha=0.3, linestyle='--')\n",
    "\n",
    "# Add value labels on bars\n",
    "for i, (bar, time) in enumerate(zip(bars, sorted_times)):\n",
    "    if time > 0:\n",
    "        ax1.text(time + max(sorted_times) * 0.02, i, f\"{time:.2f}s\", \n",
    "                va='center', fontsize=10, fontweight='bold')\n",
    "\n",
    "# Add legend for colors\n",
    "from matplotlib.patches import Patch\n",
    "legend_elements = [\n",
    "    Patch(facecolor=color_map['json'], label='Valid JSON', alpha=0.7),\n",
    "    Patch(facecolor=color_map['txt'], label='Invalid JSON (Text)', alpha=0.7),\n",
    "    Patch(facecolor=color_map['error'], label='Error', alpha=0.7),\n",
    "    Patch(facecolor=color_map['unknown'], label='Unknown', alpha=0.7)\n",
    "]\n",
    "ax1.legend(handles=legend_elements, loc='lower right', fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(CMP_DIR / \"execution_time_comparison.png\", dpi=300, bbox_inches='tight')\n",
    "print(f\"\\nüìà Execution time plot saved to: {(CMP_DIR / 'execution_time_comparison.png').absolute()}\")\n",
    "plt.show()\n",
    "\n",
    "# ============================================\n",
    "# PLOT 2: RESPONSE TYPE DISTRIBUTION\n",
    "# ============================================\n",
    "response_type_counts = {\n",
    "    \"json\": response_types.count(\"json\"),\n",
    "    \"txt\": response_types.count(\"txt\"),\n",
    "    \"error\": response_types.count(\"error\"),\n",
    "    \"unknown\": response_types.count(\"unknown\")\n",
    "}\n",
    "\n",
    "# Filter out zero counts\n",
    "response_type_counts = {k: v for k, v in response_type_counts.items() if v > 0}\n",
    "\n",
    "fig2, ax2 = plt.subplots(figsize=(10, 8))\n",
    "\n",
    "wedges, texts, autotexts = ax2.pie(\n",
    "    response_type_counts.values(),\n",
    "    labels=[k.upper() for k in response_type_counts.keys()],\n",
    "    colors=[color_map[k] for k in response_type_counts.keys()],\n",
    "    autopct='%1.1f%%',\n",
    "    startangle=90,\n",
    "    textprops={'fontsize': 12, 'fontweight': 'bold'},\n",
    "    explode=[0.05] * len(response_type_counts)  # Slightly separate slices\n",
    ")\n",
    "\n",
    "ax2.set_title(\"Response Type Distribution\", fontsize=16, fontweight=\"bold\", pad=20)\n",
    "\n",
    "# Make percentage text bold and white\n",
    "for autotext in autotexts:\n",
    "    autotext.set_color('white')\n",
    "    autotext.set_fontweight('bold')\n",
    "    autotext.set_fontsize(14)\n",
    "\n",
    "# Make label text bold\n",
    "for text in texts:\n",
    "    text.set_fontweight('bold')\n",
    "    text.set_fontsize(12)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(CMP_DIR / \"response_type_distribution.png\", dpi=300, bbox_inches='tight')\n",
    "print(f\"üìà Response type plot saved to: {(CMP_DIR / 'response_type_distribution.png').absolute()}\")\n",
    "plt.show()\n",
    "\n",
    "# ============================================\n",
    "# PLOT 3: SCHEMA COMPLIANCE CHECK\n",
    "# ============================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"Checking schema compliance...\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Required fields from the schema\n",
    "REQUIRED_FIELDS = [\n",
    "    \"title\", \"job_function\", \"seniority_level\", \"industry\", \"department\",\n",
    "    \"job_family\", \"specialization\", \"min_salary\", \"max_salary\", \"salary_currency\",\n",
    "    \"salary_period\", \"commission_available\", \"bonus_structure\", \"minimum_education\",\n",
    "    \"preferred_education\", \"experience_years\", \"experience_level_required\",\n",
    "    \"languages\", \"language_proficiency\", \"hard_skills\", \"soft_skills\",\n",
    "    \"certifications\", \"licenses_required\", \"responsibilities\", \"employment_type\",\n",
    "    \"contract_type\", \"work_schedule\", \"shift_details\", \"hours_per_week\",\n",
    "    \"remote_work\", \"travel_required\", \"travel_percentage\", \"street_address\",\n",
    "    \"city\", \"region\", \"postal_code\", \"country\", \"full_address\",\n",
    "    \"multiple_locations\", \"relocation_offered\", \"company_name\", \"company_size\",\n",
    "    \"company_type\", \"contact_email\", \"contact_phone\", \"contact_person\",\n",
    "    \"application_url\", \"benefits\", \"work_environment\", \"professional_development\",\n",
    "    \"work_life_balance\", \"physical_requirements\", \"work_conditions\",\n",
    "    \"special_requirements\", \"posting_date\", \"source_url\", \"job_board\", \"posting_id\"\n",
    "]\n",
    "\n",
    "compliance_results = []\n",
    "\n",
    "for model_dir in CMP_DIR.iterdir():\n",
    "    if not model_dir.is_dir():\n",
    "        continue\n",
    "    \n",
    "    model_name = model_dir.name\n",
    "    json_file = model_dir / \"response.json\"\n",
    "    \n",
    "    if not json_file.exists():\n",
    "        compliance_results.append({\n",
    "            \"model\": model_name,\n",
    "            \"has_json\": False,\n",
    "            \"fields_present\": 0,\n",
    "            \"fields_missing\": len(REQUIRED_FIELDS),\n",
    "            \"compliance_percentage\": 0\n",
    "        })\n",
    "        continue\n",
    "    \n",
    "    try:\n",
    "        with open(json_file, \"r\", encoding=\"utf-8\") as f:\n",
    "            data = json.load(f)\n",
    "        \n",
    "        fields_present = sum(1 for field in REQUIRED_FIELDS if field in data)\n",
    "        fields_missing = len(REQUIRED_FIELDS) - fields_present\n",
    "        compliance_percentage = (fields_present / len(REQUIRED_FIELDS)) * 100\n",
    "        \n",
    "        compliance_results.append({\n",
    "            \"model\": model_name,\n",
    "            \"has_json\": True,\n",
    "            \"fields_present\": fields_present,\n",
    "            \"fields_missing\": fields_missing,\n",
    "            \"compliance_percentage\": compliance_percentage\n",
    "        })\n",
    "        \n",
    "        print(f\"‚úì {model_name}: {fields_present}/{len(REQUIRED_FIELDS)} fields ({compliance_percentage:.1f}%)\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå {model_name}: Error reading JSON - {e}\")\n",
    "        compliance_results.append({\n",
    "            \"model\": model_name,\n",
    "            \"has_json\": False,\n",
    "            \"fields_present\": 0,\n",
    "            \"fields_missing\": len(REQUIRED_FIELDS),\n",
    "            \"compliance_percentage\": 0\n",
    "        })\n",
    "\n",
    "# Plot schema compliance\n",
    "fig3, ax3 = plt.subplots(figsize=(14, max(6, len(compliance_results) * 0.5)))\n",
    "\n",
    "# Sort by compliance percentage\n",
    "sorted_compliance = sorted(compliance_results, key=lambda x: x[\"compliance_percentage\"])\n",
    "comp_models = [r[\"model\"] for r in sorted_compliance]\n",
    "comp_percentages = [r[\"compliance_percentage\"] for r in sorted_compliance]\n",
    "\n",
    "# Color based on compliance level\n",
    "colors_compliance = []\n",
    "for pct in comp_percentages:\n",
    "    if pct >= 90:\n",
    "        colors_compliance.append('#2ecc71')  # Green\n",
    "    elif pct >= 70:\n",
    "        colors_compliance.append('#f39c12')  # Orange\n",
    "    elif pct > 0:\n",
    "        colors_compliance.append('#e74c3c')  # Red\n",
    "    else:\n",
    "        colors_compliance.append('#95a5a6')  # Gray\n",
    "\n",
    "bars = ax3.barh(comp_models, comp_percentages, color=colors_compliance, alpha=0.7, edgecolor='black', linewidth=0.5)\n",
    "ax3.set_xlabel(\"Schema Compliance (%)\", fontsize=13, fontweight='bold')\n",
    "ax3.set_ylabel(\"Model\", fontsize=13, fontweight='bold')\n",
    "ax3.set_title(f\"Schema Compliance: Required Fields Present ({len(REQUIRED_FIELDS)} total)\", \n",
    "              fontsize=16, fontweight=\"bold\", pad=20)\n",
    "ax3.grid(axis='x', alpha=0.3, linestyle='--')\n",
    "ax3.set_xlim(0, 105)\n",
    "\n",
    "# Add percentage labels and field counts\n",
    "for i, (bar, pct, result) in enumerate(zip(bars, comp_percentages, sorted_compliance)):\n",
    "    if pct > 0:\n",
    "        label = f\"{pct:.1f}% ({result['fields_present']}/{len(REQUIRED_FIELDS)})\"\n",
    "        ax3.text(pct + 2, i, label, va='center', fontsize=10, fontweight='bold')\n",
    "    else:\n",
    "        ax3.text(2, i, \"No JSON\", va='center', fontsize=10, fontweight='bold', color='red')\n",
    "\n",
    "# Add legend\n",
    "from matplotlib.patches import Patch\n",
    "legend_elements = [\n",
    "    Patch(facecolor='#2ecc71', label='Excellent (‚â•90%)', alpha=0.7),\n",
    "    Patch(facecolor='#f39c12', label='Good (70-89%)', alpha=0.7),\n",
    "    Patch(facecolor='#e74c3c', label='Poor (<70%)', alpha=0.7),\n",
    "    Patch(facecolor='#95a5a6', label='No JSON', alpha=0.7)\n",
    "]\n",
    "ax3.legend(handles=legend_elements, loc='lower right', fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(CMP_DIR / \"schema_compliance.png\", dpi=300, bbox_inches='tight')\n",
    "print(f\"\\nüìà Schema compliance plot saved to: {(CMP_DIR / 'schema_compliance.png').absolute()}\")\n",
    "plt.show()\n",
    "\n",
    "# Print detailed compliance stats\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SCHEMA COMPLIANCE STATISTICS\")\n",
    "print(\"=\"*80)\n",
    "valid_compliance = [r for r in compliance_results if r[\"has_json\"]]\n",
    "if valid_compliance:\n",
    "    avg_compliance = np.mean([r[\"compliance_percentage\"] for r in valid_compliance])\n",
    "    print(f\"\\nüìä Average Compliance: {avg_compliance:.1f}%\")\n",
    "    print(f\"   Models with JSON: {len(valid_compliance)}/{len(compliance_results)}\")\n",
    "    print(f\"   Perfect compliance (100%): {sum(1 for r in valid_compliance if r['compliance_percentage'] == 100)}\")\n",
    "    print(f\"   Excellent (‚â•90%): {sum(1 for r in valid_compliance if r['compliance_percentage'] >= 90)}\")\n",
    "    print(f\"   Good (70-89%): {sum(1 for r in valid_compliance if 70 <= r['compliance_percentage'] < 90)}\")\n",
    "    print(f\"   Poor (<70%): {sum(1 for r in valid_compliance if r['compliance_percentage'] < 70)}\")\n",
    "\n",
    "# ============================================\n",
    "# TABLE: FIELD COMPLIANCE RANKING\n",
    "# ============================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(f\"FIELD COMPLIANCE TABLE (Total Required: {len(REQUIRED_FIELDS)})\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Sort by fields present (descending), then by model name\n",
    "sorted_table = sorted(compliance_results, key=lambda x: (-x[\"fields_present\"], x[\"model\"]))\n",
    "\n",
    "# Print table header\n",
    "print(f\"\\n{'Rank':<6} {'Model':<45} {'Present':<10} {'Missing':<10} {'%':<8} {'Status'}\")\n",
    "print(\"-\" * 95)\n",
    "\n",
    "# Print each row\n",
    "for rank, result in enumerate(sorted_table, 1):\n",
    "    model = result[\"model\"]\n",
    "    present = result[\"fields_present\"]\n",
    "    missing = result[\"fields_missing\"]\n",
    "    pct = result[\"compliance_percentage\"]\n",
    "    \n",
    "    # Determine status\n",
    "    if not result[\"has_json\"]:\n",
    "        status = \"‚ùå NO JSON\"\n",
    "    elif pct == 100:\n",
    "        status = \"‚úÖ PERFECT\"\n",
    "    elif pct >= 90:\n",
    "        status = \"üü¢ EXCELLENT\"\n",
    "    elif pct >= 70:\n",
    "        status = \"üü† GOOD\"\n",
    "    else:\n",
    "        status = \"üî¥ POOR\"\n",
    "    \n",
    "    # Truncate model name if too long\n",
    "    model_display = model[:43] + \"..\" if len(model) > 45 else model\n",
    "    \n",
    "    print(f\"{rank:<6} {model_display:<45} {present:<10} {missing:<10} {pct:>6.1f}% {status}\")\n",
    "\n",
    "print(\"-\" * 95)\n",
    "print(f\"{'TOTAL':<6} {len(compliance_results)} models analyzed\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# ============================================\n",
    "# PRINT SUMMARY STATISTICS\n",
    "# ============================================\n",
    "# ============================================\n",
    "# SCHEMA COMPLIANCE SUMMARY IN STATS\n",
    "# ============================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SCHEMA COMPLIANCE STATISTICS\")\n",
    "print(\"=\"*80)\n",
    "valid_compliance = [r for r in compliance_results if r[\"has_json\"]]\n",
    "if valid_compliance:\n",
    "    avg_compliance = np.mean([r[\"compliance_percentage\"] for r in valid_compliance])\n",
    "    print(f\"\\nüìä Average Compliance: {avg_compliance:.1f}%\")\n",
    "    print(f\"   Models with JSON: {len(valid_compliance)}/{len(compliance_results)}\")\n",
    "    print(f\"   Perfect compliance (100%): {sum(1 for r in valid_compliance if r['compliance_percentage'] == 100)}\")\n",
    "    print(f\"   Excellent (‚â•90%): {sum(1 for r in valid_compliance if r['compliance_percentage'] >= 90)}\")\n",
    "    print(f\"   Good (70-89%): {sum(1 for r in valid_compliance if 70 <= r['compliance_percentage'] < 90)}\")\n",
    "    print(f\"   Poor (<70%): {sum(1 for r in valid_compliance if r['compliance_percentage'] < 70)}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SUMMARY STATISTICS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "valid_times = [t for t in times if t > 0]\n",
    "if valid_times:\n",
    "    print(f\"\\n‚è±Ô∏è  Execution Time:\")\n",
    "    print(f\"   Fastest: {min(valid_times):.2f}s ({models[times.index(min(valid_times))]})\")\n",
    "    print(f\"   Slowest: {max(valid_times):.2f}s ({models[times.index(max(valid_times))]})\")\n",
    "    print(f\"   Average: {np.mean(valid_times):.2f}s\")\n",
    "    print(f\"   Median: {np.median(valid_times):.2f}s\")\n",
    "\n",
    "print(f\"\\n‚úÖ Response Types:\")\n",
    "for rtype, count in response_type_counts.items():\n",
    "    print(f\"   {rtype.upper()}: {count} ({count/len(results)*100:.1f}%)\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"DETAILED RESULTS\")\n",
    "print(\"=\"*80)\n",
    "for result in results:\n",
    "    status_icon = \"‚úÖ\" if result[\"response_type\"] == \"json\" else (\"‚ö†Ô∏è\" if result[\"response_type\"] == \"txt\" else \"‚ùå\")\n",
    "    time_str = f\"{result['time']:.2f}s\" if result['time'] else \"N/A\"\n",
    "    print(f\"{status_icon} {result['model']}\")\n",
    "    print(f\"   Time: {time_str} | Type: {result['response_type']} | Status: {result['status']}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "\n",
    "# ============================================\n",
    "# TABLE: FIELD COMPLIANCE RANKING\n",
    "# ============================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(f\"FIELD COMPLIANCE TABLE (Total Required: {len(REQUIRED_FIELDS)})\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Sort by fields present (descending), then by model name\n",
    "sorted_table = sorted(compliance_results, key=lambda x: (-x[\"fields_present\"], x[\"model\"]))\n",
    "\n",
    "# Print table header\n",
    "print(f\"\\n{'Rank':<6} {'Model':<50} {'Fields':<15} {'Status'}\")\n",
    "print(\"-\" * 95)\n",
    "\n",
    "# Print each row\n",
    "for rank, result in enumerate(sorted_table, 1):\n",
    "    model = result[\"model\"]\n",
    "    present = result[\"fields_present\"]\n",
    "    missing = result[\"fields_missing\"]\n",
    "    total = len(REQUIRED_FIELDS)\n",
    "    pct = result[\"compliance_percentage\"]\n",
    "    \n",
    "    # Determine status\n",
    "    if not result[\"has_json\"]:\n",
    "        status = \"‚ùå NO JSON\"\n",
    "        fields_display = \"0/53\"\n",
    "    elif pct == 100:\n",
    "        status = \"‚úÖ PERFECT\"\n",
    "        fields_display = f\"{present}/{total}\"\n",
    "    elif pct >= 90:\n",
    "        status = \"üü¢ EXCELLENT\"\n",
    "        fields_display = f\"{present}/{total}\"\n",
    "    elif pct >= 70:\n",
    "        status = \"üü† GOOD\"\n",
    "        fields_display = f\"{present}/{total}\"\n",
    "    else:\n",
    "        status = \"üî¥ POOR\"\n",
    "        fields_display = f\"{present}/{total}\"\n",
    "    \n",
    "    # Truncate model name if too long\n",
    "    model_display = model[:48] + \"..\" if len(model) > 50 else model\n",
    "    \n",
    "    print(f\"{rank:<6} {model_display:<50} {fields_display:<15} {status}\")\n",
    "\n",
    "print(\"-\" * 95)\n",
    "print(f\"{'TOTAL':<6} {len(compliance_results)} models analyzed\")\n",
    "print(\"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "job-market-analysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
